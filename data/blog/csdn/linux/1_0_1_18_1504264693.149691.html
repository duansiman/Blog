
<h1>Linux中IP隧道</h1><h2>为什么需要IP隧道？</h2><p>没有接触过这个概念的人自然提出这样的疑问。实际上概念最初的提出很简单，为了在TCP/IP网络中传输其他协议的数据包。设想IPX协议或 X.25封装的数据包如何通过Internet网进行传输，在已经使用多年的桥接技术中是通过在源协议数据包上再套上一个IP协议头来实现，形成的IP数据包通过Internet后卸去IP头，还原成源协议数据包，传送给目的站点。对源协议数据来说，就如被IP带着过了一条隧道。利用IP隧道来传送的协议包也包括IP数据包，本文主要分析的IPIP封包就是如此，从字面来理解IPIP就对了，就是把一个IP数据包又套在一个IP包里。为什么要这么做呢？多此一举嘛。其实不然，见过一些应用就会明白，移动IP（Mobile-IP）和IP多点广播（IP-Multicast）是两个通常的例子。目前，IP隧道技术在构筑虚拟专网（ Virtual Private Network）中也显示出极大的魅力。本文也将对利用IP隧道技术构筑VPN做简单设想。 </p><p></p><h2>其他隧道</h2><p>但是linux支持的隧道不止ipip一种， ipip这种隧道只能在ip之上封装ip协议。另外一种常用的是gre，其上层可以封装任何协议。如果封装的上层协议是ip，那头部就是ip:gre:ip，而ipip的头部则是ip:ip。另外，其他种类的如mpls、ipsec使用较少。</p><p>   还有一个很新的tunnel技术就是：vxlan，从3.12版本的内核开始支持。他是把传统的路由器vlan进行了扩展，用在广域网上组管道。不再是在ip层之上的封装，而是在udp层之上从mac层开始封装。也就是说，协议的头部变为了mac:ip:udp:vxlan:mac:ip:udp，当然vxlan上层封装的可以是任何的网络类型，甚至可以跨越不同的mac类型网络。vxlan与其典型的应用open vswitch一起，构成了云时代虚拟网络的基础。其不但可以桥接网络，并且可以设置跨广域网的vlan，在跨广域网的虚拟局域网中实现QoS，还可以进行丰富的流量监控和数据包分析（其封装之上是完整的mac:ip:udp头部），这些对于以前的tunnel盲传是不可想象的。</p><p> </p><h2>背景：隧道的多种理解和实现</h2><p>Internet的研究者多年前就感到需要在网络中建立隧道，最初的理解是在网络中建立一条固定的路径，以绕过一些可能失效的网关。可以说，隧道就是一条特定的路径。这样的隧道是通过IP报头中的源路由选项来实现的，在目前看来，这个方法的缺陷十分明显。要设置源路由选项就必须知道数据包要经过的确切路径，而且目前多数路由实现中都不支持源路由。</p><p>另一个实现隧道的机制是开发一种新的IP选项，用来表明源数据包的信息，原IP头可能成为此选项的一部分。这种隧道的意义与我们所说的隧道已十分接近。但它的不足在于要对目前IP选项的实现和处理做较大的修改，也缺乏灵活性。</p><p>最后常用的一种实现方法是开发一种新的IP封包协议，仍然套用当前的IP头格式。通过IP封包，不须指明网络路径，封包就能透明地到达目的地。也可以通过封包空间把未直接连接的机器绑在一起，从而创建虚拟网络。这种方法易行、可靠、可扩展性强，Linux采用了这一方法，这也是目前我们所理解的隧道思想。</p><p> </p><h2>封包协议的结构和实现</h2><p>封包协议的实现原理十分简单。先看看通过隧道传送的数据报在网络中如何流动，为了叙述简便，我把在隧道中传送的IP数据包称为封包。设备 #，分别处于隧道的两端，分别起打包（封装）和解包（解封）的作用，在整个数据包的传送路径中，除了隧道两端的 # 设备，其他网关把数据包看成一个普通的IP包进行转发。</p><p>设备 # 就是一个封包基于的两个实现部件--封装部件和解封部件。封装和解封</p><p>部件（设备）都应当同时属于两个子网。封装部件对接收到的数据报加上封包头，然后以解封部件地址作为目的地址转发出去；而解封部件则在收到封包后，还原原数据报，转发到目的子网。</p><p>隧道的源端（封装部件）对进入隧道的数据包进行封装，形成封包。 </p><p> </p><h2>Linux中的实现</h2><p>在Linux中，隧道的实现主要基于两个文件new_tunnel.c和ipip.c。同时Linux定义了一种新的协议类型--IPIP（IPPROTO_IPIP），与上面所说封包类型类似。Linux中在IP头之上封装其他协议的机制叫做GRE，该机制会添加一个额外的GRE头部，可以与IPSec配合实现加密传输，但是ipip并没有使用gre。</p><h3>基本思路</h3><p>在Linux中IP Tunnel的实现也分为两个部件：封装部件和解封部件，分别司职发送和接 收。但这两个部分是在不同的层次以不同的方式实现的。封装部件是在数据链路层以虚设备的方式实现。所有源代码见/usr/src/linux/drivers/net/new_tunnel.c 。</p><p>为实现封装，Linux实现一个称为tunl的网络设备（类似loopback设备），此设备具有其他网络设备共有的特征，对于使用此设备的上层应用来说，对这些网络设备不加区分，调用及处理方法当然也完全一样。tunnel_init()和tunnel_xmit()是new_tunnel.c中的两个主要过程。tunnel_init()初始化与设备tunl相关的device结构。而tunnel_xmit()在从tunl设备发送数据时被调用，tunl设备作为实现IP隧道技术的封装部分，在此过程中完成对相应的数据报进行封装所需的全部操作，形成IPIP类型的IP包，并重新转发此数据包（ip_forward()）。</p><p>解封部件在IP的上层实现，系统把它作为一个虚的传输层（实际上与传输层毫无关系），具体处理见文件/usr/src/linux/net/ipv4/ipip.c。</p><p>我们知道，每一个IP数据包均交由ip_rcv函数处理，在进行一些必要的判断后，ip_rcv 对于发送给本机的数据包将交给上层处理程序。对于IPIP包来说，其处理函数是ipip_rcv（就如TCP包的处理函数是tcp_rcv一样，IP层不加区分）。也就是说，当一个目的地址为本机的封包到达后，ip_rcv函数进行一些基本检查并除去IP头，然后交由ipip_rcv解封。ipip_rcv所做的工作就是去掉封包头，还原数据包，然后把还原后的数据包放入相应的</p><p> </p><h3>接收队列（netif_rx()）。</h3><p>从以上IP Tunnel实现的思想来看，思路十分清晰，但由于IP Tunnel的特殊性，其实现的层次并不单纯。实际上，它的封装和解封部件不能简单地象上面所说的那样分层。tunl设备虽应算进链路层，但其发送程序中做了更多的工作，如制作IPIP头及新的IP头（这些一般认为是传输层或网络层的工作），调用ip_forward转发新包也不是一个网络设备应当做的事。可以说，tunl借网络设备之名，一把抓干了不少工作，真是‘高效’。而解封部件宏观上看在网络层之上，解出IPIP头，恢复原数据包是它分内的事，但在它解出数据包（即原完整的协议数据包）后，它把这个包放入相应的协议接收队列。这种事可不是一个上层协议干的，这是网络设备中断接收程序的义务。看到了，在这点上，它好象到了数据链路层。</p>   &#13;
