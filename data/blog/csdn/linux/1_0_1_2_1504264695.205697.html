

<h2>用户端内核内存参数调整</h2>&#13;
<h3>/proc/sys/vm/ （需要根据内核版本调整）</h3>&#13;
<h4>交换相关</h4>&#13;
<h5>swap_token_timeout</h5>&#13;
<p> Thisfile contains valid hold time of swap out protection token. The Linux VM hastoken based thrashing control mechanism and uses the token to preventunnecessary page faults in thrashing situation. The unit of the value issecond. The value would be useful&#13;
 to tune thrashing behavior. This tunable wasremoved in 2.6.20 when the algorithm got improved.&#13;
</p>&#13;
<h5>swappiness </h5>&#13;
<p>swappiness is aparameter which sets the kernel's balance between reclaiming pages from thepage cache and swapping process memory. The default value is 60. If you wantkernel to swap out more process memory and thus cache more file contentsincrease the value.&#13;
 Otherwise, if you would like kernel to swap less decreaseit. </p>&#13;
<h5>page-cluster </h5>&#13;
<p>page-cluster controls the number of pageswhich are written to swap in a single attempt. The swap I/O size. It is alogarithmic value - setting it to zero means "1 page", setting it to1 means "2 pages", setting it to 2 means "4 pages", etc.The default value&#13;
 is three (eight pages at a time). There may be some smallbenefits in tuning this to a different value if your workload isswap-intensive.&#13;
</p>&#13;
<p> </p>&#13;
<h4>文件缓存相关</h4>&#13;
<h5>vfs_cache_pressure</h5>&#13;
<p> Controls the tendency of the kernel to reclaimthe memory which is used for caching of directory and inode objects. At thedefault value of vfs_cache_pressure = 100 the kernel will attempt to reclaimdentries and inodes at a "fair" rate with respect to pagecache&#13;
 andswapcache reclaim. Decreasing vfs_cache_pressure causes the kernel to prefer toretain dentry and inode caches. Increasing vfs_cache_pressure beyond 100 causesthe kernel to prefer to reclaim dentries and inodes.</p>&#13;
<h5>nr_pdflush_threads </h5>&#13;
<p>The count of currently-running pdflushthreads. This is a read-only value. </p>&#13;
<h5>min_free_kbytes    </h5>&#13;
<p>This is used toforce the Linux VM to keep a minimum number of kilobytes free. The VM uses thisnumber to compute a pages_min value for each lowmem zone in the system. Eachlowmem zone gets a number of reserved free pages based proportionally on itssize.&#13;
</p>&#13;
<h5>dirty_background_ratio    </h5>&#13;
<p>参数dirty_background_ratio是当所有被更改页面总大小占工作内存超过 一定比例时，pdflush 会开始写回工作。用户可以增加这个比例，以增加页面驻留在内存的时间。&#13;
</p>&#13;
<h5>dirty_expire_centisecs   </h5>&#13;
<p>参数dirty_expire_centisecs控制一个更改过的页面经过多长时间后被认为是过期的、必须被写回的页面。</p>&#13;
<h5>dirty_ratio     </h5>&#13;
<p>Contains, as a percentage of total systemmemory, the number of pages at which a process which is generating disk writeswill itself start writing out dirty data.&#13;
</p>&#13;
<h5>dirty_writeback_centisecs    </h5>&#13;
<p>参数dirty_writeback_centisecs 是在pdflash线程周期唤醒的时间间隔。也就是每过一定时间pdflsh就会将修改过得数据回写到磁盘。</p>&#13;
<h5>drop_caches  </h5>&#13;
<p>Writing to thiswill cause the kernel to drop clean caches, dentries and inodes from memory,causing that memory to become free. To free pagecache:</p>&#13;
<p>echo 1 &gt; /proc/sys/vm/drop_caches</p>&#13;
<p>To free dentries and inodes:</p>&#13;
<p>echo 2 &gt; /proc/sys/vm/drop_caches</p>&#13;
<p>To free pagecache, dentries and inodes:</p>&#13;
<p>echo 3 &gt; /proc/sys/vm/drop_caches</p>&#13;
<p>As this is a non-destructive operation, anddirty objects are not freeable, the user should run "sync" first inorder to make sure all cached objects are freed. This tunable was added in2.6.16.</p>&#13;
<h5>laptop_mode </h5>&#13;
<p>在“笔记本模式”下，内核更智能的使用 I/O 系统，它会尽量使磁盘处于低能耗的状态下。“笔记本模式”会将许多的 I/O 操作组织在一起，一次完成，而在每次的磁盘 I/O之间是默认长达 10 分钟的非活动期，这样会大大减少磁盘启动的次数。为了完成这么长时间的非活动期，内核就要在一次活动期时完成尽可能多的 I/O 任务。在一次活动期间，要完成大量的预读，然后将所有的缓冲同步。</p>&#13;
<p> </p>&#13;
<h4>内存分配相关</h4>&#13;
<h5>percpu_pagelist_fraction </h5>&#13;
<p>This is thefraction of pages at most (high mark pcp-&gt;high) in each zone that areallocated for each per cpu page list. The min value for this is 8. It meansthat we don't allow more than 1/8th of pages in each zone to be allocated inany single per_cpu_pagelist.&#13;
 This entry only changes the value of hot per cpupagelists. User can specify a number like 100 to allocate 1/100th of each zoneto each per cpu page list. The batch value of each per cpu pagelist is alsoupdated as a result. It is set to pcp-&gt;high / 4. The upper&#13;
 limit of batch is(PAGE_SHIFT * 8). The initial value is zero. Kernel does not use this value atboot time to set the high water marks for each per cpu page list.</p>&#13;
<h5>overcommit_memory </h5>&#13;
<p>Controlsovercommit of system memory, possibly allowing processes to allocate (but notuse) more memory than is actually available.</p>&#13;
<p>0 - Heuristic overcommit handling. Obviousovercommits of address space are refused. Used for a typical system. It ensuresa seriously wild allocation fails while allowing overcommit to reduce swapusage. root is allowed to allocate slighly more memory in this&#13;
 mode. This isthe default.</p>&#13;
<p>1 - Always overcommit. Appropriate for somescientific applications.</p>&#13;
<p>2 - Don't overcommit. The total addressspace commit for the system is not permitted to exceed swap plus a configurablepercentage (default is 50) of physical RAM. Depending on the percentage you use,in most situations this means a process will not be killed&#13;
 while attempting touse already-allocated memory but will receive errors on memory allocation asappropriate.</p>&#13;
<h5>overcommit_ratio</h5>&#13;
<p> Percentage of physical memory size to includein overcommit calculations. Memory allocation limit = swapspace + physmem *(overcommit_ratio / 100) swapspace = total size of all swap areas</p>&#13;
<p>physmem = size of physical memory in system</p>&#13;
<h5>max_map_count   </h5>&#13;
<p>This filecontains the maximum number of memory map areas a process may have. Memory mapareas are used as a side-effect of calling malloc, directly by mmap andmprotect, and also when loading shared libraries. While most applications needless than a thousand&#13;
 maps, certain programs, particularly malloc debuggers, mayconsume lots of them, e.g., up to one or two maps per allocation. The defaultvalue is 65536.&#13;
</p>&#13;
<h5>mmap_min_addr     </h5>&#13;
<p>This fileindicates the amount of address space which a user process will be restrictedfrom mmaping. Since kernel null dereference bugs could accidentally operatebased on the information in the first couple of pages of memory userspaceprocesses should not&#13;
 be allowed to write to them.    By default this value is set to 0 and noprotections will be enforced by the security module. Setting this value tosomething like 64k will allow the vast majority of applications to workcorrectly and provide defense in depth&#13;
 against future potential kernel bugs.</p>&#13;
<h5>lowmem_reserve_ratio </h5>&#13;
<p>Ratio of totalpages to free pages for each memory zone.</p>&#13;
<h5>legacy_va_layout   </h5>&#13;
<p>If non-zero,this sysctl disables the new 32-bit mmap map layout - the kernel will use thelegacy (2.4) layout for all processes</p>&#13;
<p> </p>&#13;
<h4>其他</h4>&#13;
<h5>block_dump    </h5>&#13;
<p>参数block_dump使块I / O调试时设置为一个非零的值。如果你想找出哪些过程引起的磁盘旋转（见/proc/sys/vm/laptop_mode），你可以通过设置标志收集信息。设置该标志后，Linux将会以文件的形式报告所有磁盘活动时的读写操作以及所有脏块。这使得它可以解释为什么一个磁盘需要旋转起来，甚至可以增加电池寿命。把block_dump输出写至内核输出，可以使用“dmesg”相关信息。当你使用block_dump和内核日志记录级别，还包括内核调试信息，你可能要关闭klogd，否则block_dump输出将被记录，导致不正常的磁盘活动有。</p>&#13;
<h5>hugepages_treat_as_movable </h5>&#13;
<p>When a non-zerovalue is written to this tunable, future allocations for the huge page poolwill use ZONE_MOVABLE. Despite huge pages being non-movable, we do notintroduce additional external fragmentation of note as huge pages are alwaysthe largest contiguous&#13;
 block we care about. Huge pages are not movable so are notallocated from ZONE_MOVABLE by default. However, as ZONE_MOVABLE will alwayshave pages that can be migrated or reclaimed, it can be used to satisfyhugepage allocations even when the system has been&#13;
 running a long time. Thisallows an administrator to resize the hugepage pool at runtime depending on thesize of ZONE_MOVABLE.</p>&#13;
<h5>hugetlb_shm_group   </h5>&#13;
<p>hugetlb_shm_groupcontains group id that is allowed to create SysV shared memory segment usinghugetlb page</p>&#13;
<h5>nr_hugepages </h5>&#13;
<p>nr_hugepages configures number of hugetlbpage reserved for the system. </p>&#13;
<h5>numa_zonelist_order </h5>&#13;
<p>This sysctl is only for NUMA. 'Where thememory is allocated from' is controlled by zonelists. In non-NUMA case, azonelist for GFP_KERNEL is ordered as following: ZONE_NORMAL -&gt; ZONE_DMA.This means that a memory allocation request for GFP_KERNEL will get&#13;
 memory fromZONE_DMA only when ZONE_NORMAL is not available. In NUMA case, you can think offollowing 2 types of order. Assume 2 node NUMA and below is zonelist ofNode(0)'s GFP_KERNEL:</p>&#13;
<p>(A) Node(0) ZONE_NORMAL -&gt; Node(0)ZONE_DMA -&gt; Node(1) ZONE_NORMAL</p>&#13;
<p>(B) Node(0) ZONE_NORMAL -&gt; Node(1)ZONE_NORMAL -&gt; Node(0) ZONE_DMA. Type(A) offers the best locality forprocesses on Node(0), but ZONE_DMA will be used before ZONE_NORMAL exhaustion.This increases possibility of out-of-memory (OOM) of ZONE_DMA because ZONE_DMAis&#13;
 tend to be small. Type(B) cannot offer the best locality but is more robustagainst OOM of the DMA zone. Type(A) is called as "Node" order. Type(B) is "Zone" order. "Node order" orders the zonelists bynode, then by zone within each node. Specify "[Nn]ode" for&#13;
 nodeorder. "Zone Order" orders the zonelists by zone type, then by nodewithin each zone. Specify "[Zz]one" for zone order. Specify"[Dd]efault" to request automatic configuration. Autoconfigurationwill select "node" order in following case:</p>&#13;
<p>(1) if the DMA zone does not exist or</p>&#13;
<p>(2) if the DMA zone comprises greater than50% of the available memory or</p>&#13;
<p>(3) if any node's DMA zone comprisesgreater than 60% of its local memory and the amount of local memory is bigenough. Otherwise, "zone" order will be selected. Default order isrecommended unless this is causing problems for your system/application.</p>&#13;
<h5>panic_on_oom</h5>&#13;
<p> This enables or disables panic onout-of-memory feature. If this is set to 1, the kernel panics whenout-of-memory happens. If this is set to 0, the kernel will kill some rogueprocess, by calling oom_kill(). Usually, oom_killer can kill rogue processesand&#13;
 system will survive. If you want to panic the system rather than killingrogue processes, set this to 1. The default value is 0.&#13;
</p>&#13;
<h5>stat_interval </h5>&#13;
<p>With this tunable you can configure VMstatistics update interval. The default value is 1. This tunable first appearedin 2.6.22 kernel.&#13;
</p>&#13;
<h5>vdso_enabled</h5>&#13;
<p> Whenthis flag is set, the kernel maps a vDSO page into newly created processes andpasses its address down to glibc upon exec(). This feature is enabled bydefault. vDSO is a virtual DSO (dynamic shared object) exposed by the kernel atsome address in every&#13;
 process' memory. It's purpose is to speed up systemcalls. The mapping address used to be fixed (0xffffe000), but starting with2.6.18 it's randomized (besides the security implications, this also helpsdebuggers&#13;
</p>&#13;
<p> </p>&#13;
<p> </p>&#13;
<p> </p>&#13;
<h2>相关系统调用API</h2>&#13;
<h2>相关内核调用API</h2>&#13;
<h1>Linux性能工具</h1>&#13;
<h2>性能监控工具</h2>&#13;
<p><img src="http://img.blog.csdn.net/20150825205210369?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="" /></p>&#13;
<h2>性能测试工具</h2>&#13;
<div><img src="http://img.blog.csdn.net/20150825205239859?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="" /><br />&#13;
</div>&#13;
<p></p>&#13;
<h2>性能优化工具</h2>&#13;
<div><img src="http://img.blog.csdn.net/20150825205311721?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt="" /><br />&#13;
</div>&#13;
   &#13;
