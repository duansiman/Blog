\n\n<pre><a target="_blank" href="http://blog.csdn.net/l1028386804/article/details/46496123">转载请注明出处:http://blog.csdn.net/l1028386804/article/details/46496123</a>\n</pre>&#13;\n<h3>1.Hive</h3>&#13;\n1.1在hadoop生态圈中属于数据仓库的角色。他能够管理hadoop中的数据，同时可以查询hadoop中的数据。<br />&#13;\n  本质上讲，hive是一个SQL解析引擎。Hive可以把SQL查询转换为MapReduce中的job来运行。<br />&#13;\n  hive有一套映射工具，可以把SQL转换为MapReduce中的job，可以把SQL中的表、字段转换为HDFS中的文件(夹)以及文件中的列。<br />&#13;\n  这套映射工具称之为metastore，一般存放在derby、mysql中。<br />&#13;\n1.2 hive在hdfs中的默认位置是/user/hive/warehouse，是由配置文件hive-conf.xml中属性hive.metastore.warehouse.dir决定的。<br />&#13;\n<h3>2.hive的安装</h3>&#13;\n<h4>  (1)解压缩、重命名、设置环境变量</h4>&#13;\n<h4>  (2)修改配置文件</h4>&#13;\n<p>     在目录$HIVE_HOME/conf/下，执行命令mv hive-default.xml.template  hive-site.xml重命名</p>&#13;\n     在目录$HIVE_HOME/conf/下，执行命令mv hive-env.sh.template  hive-env.sh重命名<br />&#13;\n<h4>  (3)修改hadoop的配置文件hadoop-env.sh</h4>&#13;\n<p>    修改内容如下：</p>&#13;\n     export HADOOP_CLASSPATH=.:$CLASSPATH:$HADOOP_CLASSPATH:$HADOOP_HOME/bin<br />&#13;\n<h4>  (4)在目录$HIVE_HOME/bin下面，修改文件hive-config.sh</h4>&#13;\n<p>      增加以下内容：</p>&#13;\n     export JAVA_HOME=/usr/local/jdk<br />&#13;\n     export HIVE_HOME=/usr/local/hive<br />&#13;\n     export HADOOP_HOME=/usr/local/hadoop<br />&#13;\n<h3>3.安装mysql</h3>&#13;\n<h4>  (1)删除linux上已经安装的mysql相关库信息。</h4>&#13;\n<p>     rpm  -e  xxxxxxx   --nodeps  其中xxxxxxx是用 rpm -qa |grep mysql 命令查出的完整的数据库名称<br />&#13;\n</p>&#13;\n     执行命令rpm -qa |grep mysql 检查是否删除干净<br />&#13;\n<h4>  (2)执行命令 rpm -i   mysql-server-********  安装mysql服务端     </h4>&#13;\n<h4>  (3)启动mysql 服务端，执行命令  mysqld_safe &amp;</h4>&#13;\n<h4>  (4)执行命令 rpm -i   mysql-client-********  安装mysql客户端</h4>&#13;\n<h4>  (5)执行命令mysql_secure_installation设置root用户密码</h4>&#13;\n<h3>4. 使用mysql作为hive的metastore</h3>&#13;\n<h4>  (1)把mysql的jdbc驱动放置到hive的lib目录下</h4>&#13;\n<h4>  (2)修改hive-site.xml文件</h4>&#13;\n<p>  修改内容如下：  <br />&#13;\n</p>&#13;\n<pre name="code" class="html"> &lt;property&gt;\n &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;\n &lt;value&gt;jdbc:mysql://hadoop0:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;\n &lt;/property&gt;\n &lt;property&gt;\n &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;\n &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;\n &lt;/property&gt;\n &lt;property&gt;\n &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;\n &lt;value&gt;root&lt;/value&gt;\n &lt;/property&gt;\n &lt;property&gt;\n &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;\n &lt;value&gt;admin&lt;/value&gt;\n &lt;/property&gt;</pre>&#13;\n<h3>5. 内部表</h3>&#13;\n   CREATE TABLE t1(id int);  <br />&#13;\n   LOAD DATA LOCAL INPATH '/root/id' INTO TABLE t1;<br />&#13;\n   CREATE TABLE t2(id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\t';<br />&#13;\n<h3>6. 分区表</h3>&#13;\n   CREATE TABLE t3(id int) PARTITIONED BY (day int);  <br />&#13;\n   LOAD DATA LOCAL INPATH '/root/id' INTO TABLE t1 PARTITION (day=22);   <br />&#13;\n<h3>7. 桶表</h3>&#13;\n   create table t4(id int) clustered by(id) into 4 buckets; <br />&#13;\n   set hive.enforce.bucketing = true;<br />&#13;\n   insert into table t4 select id from t3;<br />&#13;\n<h3>8. 外部表</h3>&#13;\n   create external table t5(id int) location '/external';  <br />&#13;\n &#13;\n
